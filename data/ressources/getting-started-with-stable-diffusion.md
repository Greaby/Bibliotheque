---
authors: ["Jon Stokes"]
type: [Article]
category: [Tech]
tag:
    [
        "Stable diffusion",
        "image to image",
        "text to image",
        "AI art",
        "Dall-e",
        NightCafe,
        "Dream studio",
        "PlaygroundAI",
        "Krea.ai",
        "Lexica.art",
        "Arthub.ai",
        "DiffusionBee",
    ]
---

# Getting Started With Stable Diffusion: A Guide For Creators

https://www.jonstokes.com/p/getting-started-with-stable-diffusion

This is the latest, application-focused installment of my series on AI content generation. Part 1 covers machine learning basics, and Part 2 explains the details of tasks and models. In the present piece, I regularly refer back to the concepts explained in these first two installments, so you’ll want to read those if you haven’t already.

Please consider subscribing so you don’t miss any future tutorials!

With the open-source release of Stable Diffusion in August 2022, content creators who want to get started with AI image generation now have an affordable option with three critical advantages over Open AI’s DALL-E 2:

    It’s open to developers to implement in their apps without any oversight or censorship from the model maker. (Compare DALL-E 2’s terms of use, which they will enforce.)

    It’s capable of producing images that DALL-E 2 will not due to copyright or “AI safety” reasons.

    You own the images you produce. (Compare OpenAI’s ownership of all the images produced by its DALL-E models.)

For now, DALL-E 2 is still where it’s at for photorealistic images, but if you can make more artistic and artificial-looking images work for your application, then you have a rapidly growing menu of Stable Diffusion-based options to choose from.

But wow, there are already a lot of ways to run Stable Diffusion — it’s overwhelming. (At least, I personally find it pretty overwhelming!) But if you’re willing to invest a little time into learning the basics, you can get started without spending any money at all.
